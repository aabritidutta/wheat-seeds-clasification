{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network using Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A feed forward network on a classification problem using Stochastic Gradient Descent for optimisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About Dataset\n",
    "This dataset contains instances of 3 different varieties of wheat: Kama, Rosa and Canadian based on diffrent parameters and characteristics of the the wheat seeds.\n",
    "Source : https://www.kaggle.com/rwzhang/seeds-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing all required library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialising random weights and parameters\n",
    "def initialize_parameters(layers_size):\n",
    "    #print(\"2. InitializeParameter\")\n",
    "    np.random.seed(73)\n",
    "\n",
    "    for l in range(1, len(layers_size)):\n",
    "        #print(\"no of layers\",len(layers_size))\n",
    "        parameters[\"W\" + str(l)] = np.random.randn(layers_size[l], layers_size[l - 1])\n",
    "        parameters[\"b\" + str(l)] = np.zeros((layers_size[l], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining Sigmoid Function\n",
    "def sigmoid(a):\n",
    "    return 1 / (1 + np.exp(-a))\n",
    "\n",
    "#Defining Sofmax Function\n",
    "def softmax(a):\n",
    "        expZ = np.exp(a - np.max(a))\n",
    "        return expZ / expZ.sum(axis=0, keepdims=True)\n",
    "\n",
    "#Defining a function to calculate the sigmoid derivative\n",
    "def sigmoid_derivative(a):\n",
    "        s = 1 / (1 + np.exp(-a))\n",
    "        return s * (1 - s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Forward Propogation\n",
    "def forward(X):\n",
    "    store = {}\n",
    "\n",
    "    h = X.T\n",
    "    for l in range(L - 1):\n",
    "        a = parameters[\"W\" + str(l + 1)].dot(h) + parameters[\"b\" + str(l + 1)]  # Updating pre-activation layers\n",
    "        h = sigmoid(a)  ### Appying sigmoid activation function\n",
    "        \n",
    "        store[\"h\" + str(l + 1)] = h\n",
    "        store[\"W\" + str(l + 1)] = parameters[\"W\" + str(l + 1)]\n",
    "        store[\"a\" + str(l + 1)] = a\n",
    "        \n",
    "    a = parameters[\"W\" + str(L)].dot(h) + parameters[\"b\" + str(L)]\n",
    "    h = softmax(a) ## Softmax Function as output function\n",
    "\n",
    "    store[\"h\" + str(L)] = h\n",
    "    store[\"W\" + str(L)] = parameters[\"W\" + str(L)]\n",
    "    store[\"a\" + str(L)] = a\n",
    "    return h, store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Backward propagation Function\n",
    "def backward(X, Y, store):\n",
    "\n",
    "    derivatives = {}\n",
    "\n",
    "    store[\"h0\"] = X.T\n",
    "    \n",
    "    # Calculating the derivatives of loss wrt to parameters\n",
    "    h = store[\"h\" + str(L)]\n",
    "    da = h - Y.T\n",
    "    dW = da.dot(store[\"h\" + str(L - 1)].T)\n",
    "    db = np.sum(da,axis=1, keepdims=True)\n",
    "    dhPrev = store[\"W\" + str(L)].T.dot(da)\n",
    "\n",
    "    derivatives[\"dW\" + str(L)] = dW\n",
    "    derivatives[\"db\" + str(L)] = db\n",
    "    \n",
    "    # Calculating the derivatives in the hidden layers\n",
    "    for l in range(L-1 , 0, -1):\n",
    "        da = dhPrev * sigmoid_derivative(store[\"a\" + str(l)])\n",
    "        dW = da.dot(store[\"h\" + str(l-1)].T)\n",
    "        db = np.sum(da,axis=1,keepdims=True)\n",
    "        if l > 1:\n",
    "            dhPrev = store[\"W\" + str(l)].T.dot(da)\n",
    "        derivatives[\"dW\" + str(l)] = dW\n",
    "        derivatives[\"db\" + str(l)] = db\n",
    "    return derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the accuracy of the model\n",
    "def predict(X, Y):\n",
    "    h, cache = forward(X)\n",
    "    y_hat = np.argmax(h, axis=0)\n",
    "    Y = np.argmax(Y, axis=1)\n",
    "    accuracy = (y_hat == Y).mean()\n",
    "    return accuracy * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot epochs vs error\n",
    "def plot_cost():\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(len(costs)), costs)\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(\"error\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to pre-process the data by normalising the data, splitting the data into train and test and converting the target column into one-hot vector\n",
    "def pre_process_data():\n",
    "    #loading the dataset \n",
    "    dataset = pd.read_table('seeds_dataset.txt', delim_whitespace=True, names=('A', 'P', 'C', 'L', 'W', 'AC', 'LK','Out'), index_col=False)\n",
    "    \n",
    "    #normalising the dataset\n",
    "    normalized = preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "    normalised_dataset= normalized.fit_transform(dataset)\n",
    "\n",
    "    X_data=dataset[['A', 'P', 'C', 'L', 'W', 'AC', 'LK']]\n",
    "    Y_data=dataset[['Out']]\n",
    "    \n",
    "    # splitting the data into train and test set\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X_data, Y_data, test_size=0.33)\n",
    "    normalized = preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "    scaled_training = normalized.fit_transform(X_train)\n",
    "    scaled_testing = normalized.transform(X_test)\n",
    "    \n",
    "    y_train=Y_train.to_numpy(copy=True)\n",
    "    y_test=Y_test.to_numpy(copy=True)\n",
    "    \n",
    "    # converting the target variable into one-hot vector\n",
    "    enc = OneHotEncoder(sparse=False, categories='auto')\n",
    "    Y_Scaled_train = enc.fit_transform(y_train.reshape(len(y_train), -1))\n",
    "\n",
    " \n",
    "    Y_scaled_test = enc.transform(y_test.reshape(len(y_test), -1))\n",
    " \n",
    "    return scaled_training, Y_Scaled_train, scaled_testing, Y_scaled_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train the model\n",
    "def learning(X_learn, Y_learn, noOfData, learning_rate, n_iterations):\n",
    "    random.shuffle(noOfData)\n",
    "    for loop in range(n_iterations):\n",
    "        costIter=[]\n",
    "        for eachInput in noOfData:   # Considering 1 input at a time\n",
    "            X=np.array(X_learn[eachInput])\n",
    "            X=X.reshape((1,X.shape[0]))\n",
    "            Y=Y_learn[eachInput]\n",
    "            Y=Y.reshape((1,Y.shape[0]))\n",
    "            \n",
    "            h, store = forward(X)  # Performing forward propagation \n",
    "            cost = -np.sum(Y * np.log(h.T)+ 1e-8)\n",
    "            costIter.append(cost)\n",
    "            derivatives = backward(X, Y, store)  # Performing backward propagation\n",
    "        \n",
    "            for l in range(1, L + 1):   # Updating the parameters after every input\n",
    "                parameters[\"W\" + str(l)] = parameters[\"W\" + str(l)] - learning_rate * derivatives[\"dW\" + str(l)]\n",
    "                parameters[\"b\" + str(l)] = parameters[\"b\" + str(l)] - learning_rate * derivatives[\"db\" + str(l)]\n",
    "        CostArr = np.array(costIter)\n",
    "        CostMean =np.sum(CostArr)\n",
    "\n",
    "        if loop % 10 == 0:\n",
    "            print(\"cost\",CostMean)\n",
    " \n",
    "        #if loop % 10 == 0:\n",
    "        costs.append(CostMean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y = pre_process_data()\n",
    "noOfTrainData=[item for item in range(0, train_x.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamic change in size of network\n",
    "layers_dims = [8, 3]\n",
    "L = len(layers_dims)\n",
    "layers_dims.insert(0, train_x.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost 174.85287191112684\n",
      "cost 99.67376291290623\n",
      "cost 70.94953363592427\n",
      "cost 55.5365102722589\n",
      "cost 46.42362719005415\n",
      "cost 40.55654961910899\n",
      "cost 36.513004698423735\n",
      "cost 33.57339052073346\n",
      "cost 31.34367763496439\n",
      "cost 29.59335037421903\n",
      "cost 28.179968279846364\n",
      "cost 27.011406693146068\n",
      "cost 26.02574979683383\n",
      "cost 25.18000363275113\n",
      "cost 24.443466303582973\n",
      "cost 23.79367753069354\n",
      "cost 23.213857493096068\n",
      "cost 22.69123760507258\n",
      "cost 22.215943069680055\n",
      "cost 21.78022676479116\n",
      "Train Accuracy: 95.71428571428572\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "parameters = {}\n",
    "costs = []\n",
    "initialize_parameters(layers_dims)\n",
    "learning(train_x, train_y, noOfTrainData, learning_rate=0.01, n_iterations=200)\n",
    "print(\"Train Accuracy:\", predict(train_x, train_y))\n",
    "plot_cost()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 92.85714285714286\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Accuracy:\", predict(test_x, test_y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
